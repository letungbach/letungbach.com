<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Moe on Le Tung Bach, Ph.D.</title>
    <link>https://letungbach.com/tags/moe/</link>
    <description>Recent content in Moe on Le Tung Bach, Ph.D.</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Sun, 13 Apr 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://letungbach.com/tags/moe/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>market-research</title>
      <link>https://letungbach.com/posts/market-research/</link>
      <pubDate>Sun, 13 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/market-research/</guid>
      <description>&lt;p&gt;**&lt;/p&gt;&#xA;&lt;h1 id=&#34;market-opportunities-for-ai-agents-and-multi-ai-agent-systems-in-vietnam&#34;&gt;Market Opportunities for AI Agents and Multi-AI Agent Systems in Vietnam&lt;/h1&gt;&#xA;&lt;h2 id=&#34;1-executive-summary&#34;&gt;1. Executive Summary&lt;/h2&gt;&#xA;&lt;p&gt;Vietnam&amp;rsquo;s digital landscape is undergoing a rapid transformation, presenting significant opportunities for the adoption of advanced automation technologies such as AI Agents and Multi-AI Agent systems. This report provides a comprehensive analysis of the Vietnamese market, highlighting the immediate needs across key sectors including travel tourism, real estate, customer service, logistics, and manufacturing. The analysis reveals a strong government commitment to digital transformation and AI development, coupled with a high rate of technology adoption among businesses. While the market for AI Agents and Multi-AI Agent systems is still in its early stages, specific areas like customer service automation, personalized experiences in travel tourism, and efficiency improvements in real estate show immediate promise. This report recommends a phased approach to market entry, initially focusing on these high-potential areas with tailored strategies for marketing, pricing, and customer acquisition, ultimately positioning service providers to capitalize on the transformative power of AI in Vietnam.&lt;/p&gt;</description>
    </item>
    <item>
      <title>New_LLM</title>
      <link>https://letungbach.com/posts/new-model-introduction/</link>
      <pubDate>Thu, 10 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/new-model-introduction/</guid>
      <description>&lt;p&gt;LLM model introduction&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://allenai.org/blog/olmotrace&#34;&gt;https://allenai.org/blog/olmotrace&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Self-Rag</title>
      <link>https://letungbach.com/posts/self-rag/</link>
      <pubDate>Thu, 10 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/self-rag/</guid>
      <description>&lt;p&gt;**&lt;/p&gt;&#xA;&lt;h1 id=&#34;advancing-agentic-knowledgeable-self-awareness-a-research-agenda-extending-arxiv250403553&#34;&gt;Advancing Agentic Knowledgeable Self-Awareness: A Research Agenda Extending arXiv:2504.03553&lt;/h1&gt;&#xA;&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;&#xA;&lt;p&gt;The development of artificial intelligence (AI) agents capable of complex tasks necessitates mechanisms for robust and efficient knowledge utilization. A critical aspect of this is self-awareness regarding the agent&amp;rsquo;s own knowledge state – understanding what it knows, what it doesn&amp;rsquo;t know, and when external information is required. The paper arXiv:2504.03553 introduces the concept of &amp;ldquo;agentic knowledgeable self-awareness&amp;rdquo; and proposes the &amp;ldquo;KnowSelf&amp;rdquo; method as a novel approach to instill this capability in language agents. KnowSelf utilizes special tokens and a two-stage training process to explicitly signal the agent&amp;rsquo;s perceived knowledge state and guide its information processing strategy (e.g., relying on internal parameters vs. seeking external knowledge).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Continual Learning</title>
      <link>https://letungbach.com/posts/continual-learning/</link>
      <pubDate>Wed, 02 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/continual-learning/</guid>
      <description>&lt;p&gt;**&lt;/p&gt;&#xA;&lt;h1 id=&#34;continual-learning-a-review-of-variational-dropout-mixture-of-experts-with-prompting-and-backdoor-attacks&#34;&gt;Continual Learning: A Review of Variational Dropout, Mixture of Experts with Prompting, and Backdoor Attacks&lt;/h1&gt;&#xA;&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;&#xA;&lt;p&gt;The field of machine learning has witnessed significant advancements in recent years, enabling models to achieve remarkable performance on a wide array of tasks. However, a fundamental challenge arises when these models are deployed in dynamic environments where new data or tasks are encountered sequentially. This paradigm, known as continual learning, necessitates the ability of a model to learn from a continuous stream of information without forgetting previously acquired knowledge.1 A major impediment to achieving this goal is catastrophic forgetting, a phenomenon where the learning of new information leads to a drastic decline in performance on previously learned tasks.4 Overcoming this challenge requires specialized techniques that can maintain a delicate balance between the model&amp;rsquo;s capacity to learn new tasks (plasticity) and its ability to retain old knowledge (stability).4&lt;/p&gt;</description>
    </item>
    <item>
      <title>benchmark</title>
      <link>https://letungbach.com/posts/ai-benchmark/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/ai-benchmark/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://gluebenchmark.com/leaderboard&#34;&gt;GLUE Benchmark&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Video generation benchmark&#xA;&lt;a href=&#34;https://github.com/Vchitect/VBench&#34;&gt;https://github.com/Vchitect/VBench&lt;/a&gt;&#xA;&lt;a href=&#34;https://arxiv.org/abs/2401.01651#:~:text=This%20paper%20introduces%20AIGCBench,%20a%20pioneering%20comprehensive%20and,with%20a%20primary%20focus%20on%20Image-to-Video%20%28I2V%29%20generation.&#34;&gt;AIGCBench&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/NickRiccardi/two-word-test&#34;&gt;https://github.com/NickRiccardi/two-word-test&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://codeforces.com/blog/entry/133874&#34;&gt;https://codeforces.com/blog/entry/133874&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.swebench.com/&#34;&gt;https://www.swebench.com/&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://linzhiqiu.github.io/papers/naturalbench/?fbclid=IwY2xjawJ1xCpleHRuA2FlbQIxMQABHnFZ6hln8p75Kuz4l9F4Mgow7kzEgS1GKuRYj6q-DlvUAWVVRiyVmW1SvnwQ_aem_y_RMPY4cokQHJk8TpxQwpQ&#34;&gt;https://linzhiqiu.github.io/papers/naturalbench/?fbclid=IwY2xjawJ1xCpleHRuA2FlbQIxMQABHnFZ6hln8p75Kuz4l9F4Mgow7kzEgS1GKuRYj6q-DlvUAWVVRiyVmW1SvnwQ_aem_y_RMPY4cokQHJk8TpxQwpQ&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/Baiqi-Li/NaturalBench&#34;&gt;https://github.com/Baiqi-Li/NaturalBench&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;trackingAI.org&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://llm-stats.com/&#34;&gt;https://llm-stats.com/&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://lmarena.ai/?leaderboard&#34;&gt;https://lmarena.ai/?leaderboard&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://fiction.live/stories/Fiction-liveBench-Feb-21-2025/oQdzQvKHw8JyXbN87&#34;&gt;https://fiction.live/stories/Fiction-liveBench-Feb-21-2025/oQdzQvKHw8JyXbN87&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://huggingface.co/spaces/adyen/DABstep&#34;&gt;Data Agent Benchmark&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://artificialanalysis.ai/&#34;&gt;https://artificialanalysis.ai/&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;LiveCodeBench và SciCode&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://aider.chat/docs/leaderboards/?fbclid=IwY2xjawJs18lleHRuA2FlbQIxMQABHpMzr6OCU0YD65sAyMY5vDd4DKn00s4RKJniEUvlJIIeX4sIYMCtIq7MLZw8_aem_yF2JsBDjLMvkeFDhYfb-6A&#34;&gt;Aider polyglot&lt;/a&gt;&#xA;&lt;a href=&#34;https://github.com/Aider-AI/aider&#34;&gt;github&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://livebench.ai&#34;&gt;https://livebench.ai&lt;/a&gt;&#xA;&lt;a href=&#34;https://github.com/LiveBench/LiveBench&#34;&gt;https://github.com/LiveBench/LiveBench&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://openrouter.ai/rankings&#34;&gt;https://openrouter.ai/rankings&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://arcprize.org/leaderboard?fbclid=IwY2xjawJkGOJleHRuA2FlbQIxMAABHpInxwGwuzaVHnGeNNycEGfhmweu8Xb_aBq5dhGnOHLm1qEbktYZYnqZzNmc_aem_ttSWRTegPXjvOSU1K0DAlg&#34;&gt;https://arcprize.org/leaderboard?fbclid=IwY2xjawJkGOJleHRuA2FlbQIxMAABHpInxwGwuzaVHnGeNNycEGfhmweu8Xb_aBq5dhGnOHLm1qEbktYZYnqZzNmc_aem_ttSWRTegPXjvOSU1K0DAlg&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;![[Pasted image 20250410103636.png]]&lt;/p&gt;&#xA;&lt;p&gt;EQ-Bench - Longform Creative Writing: &lt;a href=&#34;https://arxiv.org/pdf/2312.06281&#34;&gt;paper&lt;/a&gt;&#xA;![EQ-Bench][https://eqbench.com/images/eqbench3-judge-comparison.png]&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://llmbenchmark.kili-technology.com/?_gl=1&#34;&gt;https://llmbenchmark.kili-technology.com/?_gl=1&lt;/a&gt;&lt;em&gt;1y0re2j&lt;/em&gt;_gcl_au*NzA4OTAwNjM4LjE3NDQ5MjAzNDE.&lt;/p&gt;&#xA;&lt;figure&gt;&lt;img src=&#34;https://eqbench.com/images/eqbench3-judge-comparison.png&#34;&gt;&lt;figcaption&gt;&#xA;      &lt;h4&gt;Judge Comparison&lt;/h4&gt;&#xA;    &lt;/figcaption&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;p&gt;&lt;a href=&#34;https://eqbench.com/index.html&#34;&gt;EQ-Bench 3 Leaderboard&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLMtesting</title>
      <link>https://letungbach.com/posts/test/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/test/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.promptfoo.dev/&#34;&gt;https://www.promptfoo.dev/&lt;/a&gt;&#xA;&lt;a href=&#34;https://github.com/promptfoo/promptfoo&#34;&gt;https://github.com/promptfoo/promptfoo&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>mcp</title>
      <link>https://letungbach.com/posts/mcp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/mcp/</guid>
      <description>&lt;p&gt;opensource MCP:&#xA;&lt;a href=&#34;https://github.com/pietrozullo/mcp-use&#34;&gt;https://github.com/pietrozullo/mcp-use&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;![[Pasted image 20250414230045.png]]![[Pasted image 20250414230109.png]]&lt;/p&gt;&#xA;&lt;p&gt;![[Pasted image 20250416205343.png]]&lt;/p&gt;&#xA;&lt;p&gt;  &amp;ldquo;my-mcp-server-fdbeb09b&amp;rdquo;: {&lt;/p&gt;&#xA;&lt;p&gt;                &amp;ldquo;type&amp;rdquo;: &amp;ldquo;stdio&amp;rdquo;,&lt;/p&gt;&#xA;&lt;p&gt;                &amp;ldquo;command&amp;rdquo;: &amp;ldquo;@modelcontextprotocol/docker-mcp&amp;rdquo;,&lt;/p&gt;&#xA;&lt;p&gt;                &amp;ldquo;args&amp;rdquo;: []&lt;/p&gt;&#xA;&lt;p&gt;            }&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
