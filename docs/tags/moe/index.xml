<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Moe on Le Tung Bach, Ph.D.</title>
    <link>https://letungbach.com/tags/moe/</link>
    <description>Recent content in Moe on Le Tung Bach, Ph.D.</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Mon, 14 Apr 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://letungbach.com/tags/moe/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>ZhangXu</title>
      <link>https://letungbach.com/posts/zhangxu/</link>
      <pubDate>Mon, 14 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/zhangxu/</guid>
      <description>&lt;p&gt;**&lt;/p&gt;&#xA;&lt;h1 id=&#34;zhang-xu-innovation-and-expressiveness-in-tang-dynasty-calligraphy&#34;&gt;Zhang Xu: Innovation and Expressiveness in Tang Dynasty Calligraphy&lt;/h1&gt;&#xA;&lt;figure&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/4/48/Crazyzhangxu.jpg&#34;&gt;&lt;figcaption&gt;&#xA;      &lt;h4&gt;ZhangXu&lt;/h4&gt;&#xA;    &lt;/figcaption&gt;&#xA;&lt;/figure&gt;&#xA;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Abstract&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;Zhang Xu (張旭, fl. 8th century), courtesy name Bogao (伯高), stands as a seminal figure in the history of Chinese calligraphy, particularly celebrated for his revolutionary and highly expressive &amp;ldquo;wild cursive&amp;rdquo; (狂草) style. This report provides a comprehensive examination of Zhang Xu&amp;rsquo;s life and artistic contributions. It encompasses a detailed biography, an in-depth analysis of the unique characteristics of his calligraphic style, a review of existing academic literature concerning his work, an identification of gaps in current research, a formulation of research objectives and a problem statement, and proposals for future studies that could further illuminate his significance. The enduring impact of Zhang Xu&amp;rsquo;s innovative approach to calligraphy and his lasting influence on subsequent generations of calligraphers are also briefly considered.&lt;/p&gt;</description>
    </item>
    <item>
      <title>market-research</title>
      <link>https://letungbach.com/posts/market-research/</link>
      <pubDate>Sun, 13 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/market-research/</guid>
      <description>&lt;p&gt;**&lt;/p&gt;&#xA;&lt;h1 id=&#34;market-opportunities-for-ai-agents-and-multi-ai-agent-systems-in-vietnam&#34;&gt;Market Opportunities for AI Agents and Multi-AI Agent Systems in Vietnam&lt;/h1&gt;&#xA;&lt;h2 id=&#34;1-executive-summary&#34;&gt;1. Executive Summary&lt;/h2&gt;&#xA;&lt;p&gt;Vietnam&amp;rsquo;s digital landscape is undergoing a rapid transformation, presenting significant opportunities for the adoption of advanced automation technologies such as AI Agents and Multi-AI Agent systems. This report provides a comprehensive analysis of the Vietnamese market, highlighting the immediate needs across key sectors including travel tourism, real estate, customer service, logistics, and manufacturing. The analysis reveals a strong government commitment to digital transformation and AI development, coupled with a high rate of technology adoption among businesses. While the market for AI Agents and Multi-AI Agent systems is still in its early stages, specific areas like customer service automation, personalized experiences in travel tourism, and efficiency improvements in real estate show immediate promise. This report recommends a phased approach to market entry, initially focusing on these high-potential areas with tailored strategies for marketing, pricing, and customer acquisition, ultimately positioning service providers to capitalize on the transformative power of AI in Vietnam.&lt;/p&gt;</description>
    </item>
    <item>
      <title>benchmark</title>
      <link>https://letungbach.com/posts/benchmark/</link>
      <pubDate>Thu, 10 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/benchmark/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://livebench.ai/#/&#34;&gt;https://livebench.ai/#/&lt;/a&gt;&#xA;&lt;a href=&#34;https://openrouter.ai/rankings&#34;&gt;https://openrouter.ai/rankings&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://arcprize.org/leaderboard?fbclid=IwY2xjawJkGOJleHRuA2FlbQIxMAABHpInxwGwuzaVHnGeNNycEGfhmweu8Xb_aBq5dhGnOHLm1qEbktYZYnqZzNmc_aem_ttSWRTegPXjvOSU1K0DAlg&#34;&gt;https://arcprize.org/leaderboard?fbclid=IwY2xjawJkGOJleHRuA2FlbQIxMAABHpInxwGwuzaVHnGeNNycEGfhmweu8Xb_aBq5dhGnOHLm1qEbktYZYnqZzNmc_aem_ttSWRTegPXjvOSU1K0DAlg&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;![[Pasted image 20250410103636.png]]&lt;/p&gt;&#xA;&lt;p&gt;EQ-Bench - Longform Creative Writing: &lt;a href=&#34;https://arxiv.org/pdf/2312.06281&#34;&gt;paper&lt;/a&gt;&#xA;![EQ-Bench][https://eqbench.com/images/eqbench3-judge-comparison.png]&lt;/p&gt;&#xA;&lt;figure&gt;&lt;img src=&#34;https://eqbench.com/images/eqbench3-judge-comparison.png&#34;&gt;&lt;figcaption&gt;&#xA;      &lt;h4&gt;Judge Comparison&lt;/h4&gt;&#xA;    &lt;/figcaption&gt;&#xA;&lt;/figure&gt;</description>
    </item>
    <item>
      <title>New_LLM</title>
      <link>https://letungbach.com/posts/new-model-introduction/</link>
      <pubDate>Thu, 10 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/new-model-introduction/</guid>
      <description>&lt;p&gt;LLM model introduction&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://allenai.org/blog/olmotrace&#34;&gt;https://allenai.org/blog/olmotrace&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Self-Rag</title>
      <link>https://letungbach.com/posts/self-rag/</link>
      <pubDate>Thu, 10 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/self-rag/</guid>
      <description>&lt;p&gt;**&lt;/p&gt;&#xA;&lt;h1 id=&#34;advancing-agentic-knowledgeable-self-awareness-a-research-agenda-extending-arxiv250403553&#34;&gt;Advancing Agentic Knowledgeable Self-Awareness: A Research Agenda Extending arXiv:2504.03553&lt;/h1&gt;&#xA;&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;&#xA;&lt;p&gt;The development of artificial intelligence (AI) agents capable of complex tasks necessitates mechanisms for robust and efficient knowledge utilization. A critical aspect of this is self-awareness regarding the agent&amp;rsquo;s own knowledge state – understanding what it knows, what it doesn&amp;rsquo;t know, and when external information is required. The paper arXiv:2504.03553 introduces the concept of &amp;ldquo;agentic knowledgeable self-awareness&amp;rdquo; and proposes the &amp;ldquo;KnowSelf&amp;rdquo; method as a novel approach to instill this capability in language agents. KnowSelf utilizes special tokens and a two-stage training process to explicitly signal the agent&amp;rsquo;s perceived knowledge state and guide its information processing strategy (e.g., relying on internal parameters vs. seeking external knowledge).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Continual Learning</title>
      <link>https://letungbach.com/posts/continual-learning/</link>
      <pubDate>Wed, 02 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/continual-learning/</guid>
      <description>&lt;p&gt;**&lt;/p&gt;&#xA;&lt;h1 id=&#34;continual-learning-a-review-of-variational-dropout-mixture-of-experts-with-prompting-and-backdoor-attacks&#34;&gt;Continual Learning: A Review of Variational Dropout, Mixture of Experts with Prompting, and Backdoor Attacks&lt;/h1&gt;&#xA;&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;&#xA;&lt;p&gt;The field of machine learning has witnessed significant advancements in recent years, enabling models to achieve remarkable performance on a wide array of tasks. However, a fundamental challenge arises when these models are deployed in dynamic environments where new data or tasks are encountered sequentially. This paradigm, known as continual learning, necessitates the ability of a model to learn from a continuous stream of information without forgetting previously acquired knowledge.1 A major impediment to achieving this goal is catastrophic forgetting, a phenomenon where the learning of new information leads to a drastic decline in performance on previously learned tasks.4 Overcoming this challenge requires specialized techniques that can maintain a delicate balance between the model&amp;rsquo;s capacity to learn new tasks (plasticity) and its ability to retain old knowledge (stability).4&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
