<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Le Tung Bach, Ph.D.</title>
    <link>https://letungbach.com/</link>
    <description>Recent content on Le Tung Bach, Ph.D.</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Fri, 04 Apr 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://letungbach.com/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>MoE-JEPA</title>
      <link>https://letungbach.com/posts/moe-jepa2/</link>
      <pubDate>Fri, 04 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/moe-jepa2/</guid>
      <description>&lt;h1 id=&#34;research-proposal-moe-jepa-world-models-for-efficient-reinforcement-learning-and-planning&#34;&gt;Research Proposal: MoE-JEPA World Models for Efficient Reinforcement Learning and Planning&lt;/h1&gt;&#xA;&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;&#xA;&lt;p&gt;Current AI research emphasizes the development of sophisticated world models capable of understanding complex dynamics, particularly from video data, often leveraging self-supervised learning (SSL) for representation extraction. Predictive models in abstract spaces (like JEPA) are gaining prominence over generative ones. Simultaneously, Mixture of Experts (MoE) offers a way to scale neural network capacity efficiently. This proposal outlines a research approach combining these trends: developing an Action-Conditioned Mixture-of-Experts Joint-Embedding Predictive Architecture (MoE-JEPA) world model. This model will be pre-trained using self-supervision on large video datasets to learn robust visual representations and environment dynamics. The MoE structure will allow the model to efficiently capture diverse or multi-modal dynamics within an environment by routing inputs to specialized expert sub-networks. This sophisticated world model will then be integrated into a model-based Reinforcement Learning (RL) framework to enable efficient planning and decision-making for agents (e.g., robots) interacting with complex environments. We hypothesize that this approach will lead to more accurate world models, improved sample efficiency in RL, and better generalization across tasks compared to monolithic world models.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Continual Learning</title>
      <link>https://letungbach.com/posts/continual-learning/</link>
      <pubDate>Wed, 02 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/continual-learning/</guid>
      <description>&lt;p&gt;**&lt;/p&gt;&#xA;&lt;h1 id=&#34;continual-learning-a-review-of-variational-dropout-mixture-of-experts-with-prompting-and-backdoor-attacks&#34;&gt;Continual Learning: A Review of Variational Dropout, Mixture of Experts with Prompting, and Backdoor Attacks&lt;/h1&gt;&#xA;&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;&#xA;&lt;p&gt;The field of machine learning has witnessed significant advancements in recent years, enabling models to achieve remarkable performance on a wide array of tasks. However, a fundamental challenge arises when these models are deployed in dynamic environments where new data or tasks are encountered sequentially. This paradigm, known as continual learning, necessitates the ability of a model to learn from a continuous stream of information without forgetting previously acquired knowledge.1 A major impediment to achieving this goal is catastrophic forgetting, a phenomenon where the learning of new information leads to a drastic decline in performance on previously learned tasks.4 Overcoming this challenge requires specialized techniques that can maintain a delicate balance between the model&amp;rsquo;s capacity to learn new tasks (plasticity) and its ability to retain old knowledge (stability).4&lt;/p&gt;</description>
    </item>
    <item>
      <title>About</title>
      <link>https://letungbach.com/about/</link>
      <pubDate>Tue, 01 Apr 2025 17:53:32 +0700</pubDate>
      <guid>https://letungbach.com/about/</guid>
      <description>&lt;h1 id=&#34;le-tung-bach-phd&#34;&gt;Le Tung Bach, Ph.D.&lt;/h1&gt;&#xA;&lt;p&gt;&lt;strong&gt;AI Researcher &amp;amp; Tech Adoption Specialist | Sustainable Ecosystem Management | Secured &amp;gt;$97M+ ODA International Credit Funding | Art &amp;amp; Technology Innovator&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Founder: unitedcoffee.vn, mulala.art, giong.ai&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;üìû 0906 376 868 | üìç Hanoi, Vietnam | üìß &lt;a href=&#34;mailto:b@giong.ai&#34;&gt;b@giong.ai&lt;/a&gt; | üîó &lt;a href=&#34;https://orcid.org/0009-0006-3525-6710&#34;&gt;https://orcid.org/0009-0006-3525-6710&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;about&#34;&gt;About&lt;/h2&gt;&#xA;&lt;p&gt;Multidisciplinary AI expert with a Ph.D. in Management and extensive experience in research administration, grant writing, and financial oversight of large-scale research projects. Successfully secured and managed $97M+ in international ODA funding (AFD, World Bank, ADB, JAICA) and have a proven track record in grant application processes, compliance, and project monitoring. Expert at faculty support, interdisciplinary research collaboration, and optimizing research resources to enhance institutional impact. Passionate about advancing Vietnamese research institutions&amp;rsquo; access to international funding.&lt;/p&gt;</description>
    </item>
    <item>
      <title>list</title>
      <link>https://letungbach.com/posts/list-of-researchers-to-follow-up/</link>
      <pubDate>Tue, 01 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/list-of-researchers-to-follow-up/</guid>
      <description>&lt;h1 id=&#34;yann-lecun-the-future-beyond-generative-ai&#34;&gt;Yann LeCun: The Future Beyond Generative AI&lt;/h1&gt;&#xA;&lt;p&gt;12 sources&lt;/p&gt;&#xA;&lt;p&gt;The provided transcripts capture various discussions and lectures primarily focusing on the evolution, capabilities, limitations, and societal implications of artificial intelligence and deep learning.¬†&lt;strong&gt;Experts like Geoffrey Hinton, Yann LeCun, and Fei-Fei Li reflect on breakthroughs such as deep neural networks and large language models, including their own significant contributions.&lt;/strong&gt;¬†They discuss the future trajectory of AI research, highlighting the importance of world models, different learning approaches like joint embedding, and the distinctions between human and artificial intelligence.¬†&lt;strong&gt;Concerns surrounding responsible AI development, potential misuse, and the need for open-source platforms are also prominent themes.&lt;/strong&gt;¬†Additionally, personal anecdotes about the speakers&amp;rsquo; journeys and perspectives on the field enrich the content.¬†&lt;strong&gt;The conversations explore both the technical advancements and the broader philosophical and ethical questions raised by increasingly sophisticated AI.&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Moe-JEPA vs Titan vs FAN</title>
      <link>https://letungbach.com/posts/moe-jepa-vs-titan-vs-fan/</link>
      <pubDate>Tue, 01 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/moe-jepa-vs-titan-vs-fan/</guid>
      <description>&lt;p&gt;make a markdown code about the following content:&lt;/p&gt;&#xA;&lt;h1 id=&#34;comparative-analysis-of-advanced-ai-architectures-fourier-analysis-networks-google-titan-transformer-20-and-moe-jepa-world-models&#34;&gt;Comparative Analysis of Advanced AI Architectures: Fourier Analysis Networks, Google Titan Transformer 2.0, and MoE-JEPA World Models&lt;/h1&gt;&#xA;&lt;p&gt;The field of artificial intelligence has experienced remarkable evolution with several novel architectures emerging to address the limitations of conventional deep learning approaches. This research provides a comprehensive comparative analysis of three cutting-edge AI architectures: Fourier Analysis Networks (FANs), Google Titan Transformer 2.0, and Mixture of Experts Joint Embedding Predictive Architecture (MoE-JEPA) World Models. Each model employs distinct approaches to overcome current AI limitations, particularly in handling periodic structures, long-term dependencies, and context understanding. Through detailed examination of their architectures, operational mechanisms, advantages, limitations, and empirical performance, this study offers insights into their potential impact on the future trajectory of artificial intelligence research and applications.&lt;/p&gt;</description>
    </item>
    <item>
      <title>RSS News Feed</title>
      <link>https://letungbach.com/rss/</link>
      <pubDate>Tue, 01 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/rss/</guid>
      <description>&lt;h1 id=&#34;latest-tech-news&#34;&gt;Latest Tech News&lt;/h1&gt;&#xA;&lt;p&gt;This page automatically pulls the latest news from Hacker News. Stay updated with the newest developments in technology, programming, and startup culture.&lt;/p&gt;&#xA;&lt;h2 id=&#34;recent-headlines&#34;&gt;Recent Headlines&lt;/h2&gt;&#xA;&#xA;&lt;div class=&#34;hn-feed&#34;&gt;&#xA;  &lt;ul class=&#34;hn-stories&#34;&gt;&#xD;&#xA;    &lt;li class=&#34;hn-story&#34;&gt;&lt;a href=&#34;https://ergodiclabs.github.io/blog/posts/ai-mode-shift-2025-03/&#34; target=&#34;_blank&#34;&gt;Every app will become an AI app, just not in the way that you think&lt;/a&gt;&lt;/li&gt;&#xD;&#xA;    &lt;li class=&#34;hn-story&#34;&gt;&lt;a href=&#34;https://shkspr.mobi/blog/2025/03/pretty-print-html-using-php-8-4s-new-html-dom/&#34; target=&#34;_blank&#34;&gt;Pretty Print HTML Using PHP 8.4&#39;s New HTML DOM&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li class=&#34;hn-story&#34;&gt;&lt;a href=&#34;https://thiefchasegame.netlify.app&#34; target=&#34;_blank&#34;&gt;The Retro Game I&#39;ve built in 1h with Gemini 2.5 Agent&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li class=&#34;hn-story&#34;&gt;&lt;a href=&#34;http://www.seriousaboutech.com/2025/04/a-new-up-and-download-icon-in-ipados-184.html&#34; target=&#34;_blank&#34;&gt;A new up- and download icon in iPadOS 18.4&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li class=&#34;hn-story&#34;&gt;&lt;a href=&#34;https://spotai.lol/&#34; target=&#34;_blank&#34;&gt;Show HN: Spot the AI&lt;/a&gt;&lt;/li&gt;&#xD;&#xA;    &lt;li class=&#34;hn-story&#34;&gt;&lt;a href=&#34;https://www.quantamagazine.org/a-new-proof-smooths-out-the-math-of-melting-20250331/&#34; target=&#34;_blank&#34;&gt;A New Proof Smooths Out the Math of Melting&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li class=&#34;hn-story&#34;&gt;&lt;a href=&#34;https://github.com/HaloTech-Co-Ltd/openHalo&#34; target=&#34;_blank&#34;&gt;OpenHalo: MySQL-Compatible PostgreSQL with Superior Performance&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li class=&#34;hn-story&#34;&gt;&lt;a href=&#34;https://www.nytimes.com/2025/04/01/briefing/public-broadcasters-republicans-npr-pbs.html&#34; target=&#34;_blank&#34;&gt;Cutting Off NPR and PBS&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li class=&#34;hn-story&#34;&gt;&lt;a href=&#34;https://www.washington.edu/news/2025/03/31/discovery-of-quina-technology-challenges-view-of-ancient-human-development-in-east-asia/&#34; target=&#34;_blank&#34;&gt;Discovery of Quina technology challenges view of ancient human development&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li class=&#34;hn-story&#34;&gt;&lt;a href=&#34;https://www.hackster.io/news/raspberry-pi-releases-overclocking-guide-for-pi-5-2025043102&#34; target=&#34;_blank&#34;&gt;Raspberry Pi Releases Overclocking Guide for Pi 5&lt;/a&gt;&lt;/li&gt;&#xD;&#xA;    &lt;li class=&#34;hn-story&#34;&gt;&lt;a href=&#34;https://blog.mozilla.org/en/products/firefox/firefox-rolls-out-enhanced-privacy-features&#34; target=&#34;_blank&#34;&gt;Firefox Rolls Out Enhanced Privacy Features&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li class=&#34;hn-story&#34;&gt;&lt;a href=&#34;https://dev.to/devteam/introducing-dev-connect-our-new-networking-platform-2hf9&#34; target=&#34;_blank&#34;&gt;Introducing DEV Connect: Our New Networking Platform&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li class=&#34;hn-story&#34;&gt;&lt;a href=&#34;https://techcrunch.com/2025/03/30/startup-funding-recovered-q1-2025/&#34; target=&#34;_blank&#34;&gt;Startup Funding Makes Remarkable Recovery in Q1 2025&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li class=&#34;hn-story&#34;&gt;&lt;a href=&#34;https://www.eff.org/deeplinks/2025/04/why-we-need-stronger-algorithmic-transparency-laws&#34; target=&#34;_blank&#34;&gt;Why We Need Stronger Algorithmic Transparency Laws&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li class=&#34;hn-story&#34;&gt;&lt;a href=&#34;https://www.theregister.com/2025/04/01/linux_kernel_6_9_release/&#34; target=&#34;_blank&#34;&gt;Linux Kernel 6.9 Released with Major Performance Improvements&lt;/a&gt;&lt;/li&gt;&#xD;&#xA;    &lt;li class=&#34;hn-story&#34;&gt;&lt;a href=&#34;https://www.reuters.com/technology/eu-commission-announces-new-digital-skills-initiative-2025-04-01/&#34; target=&#34;_blank&#34;&gt;EU Commission Announces New Digital Skills Initiative&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li class=&#34;hn-story&#34;&gt;&lt;a href=&#34;https://thenewstack.io/webassembly-2-0-specification-finalized/&#34; target=&#34;_blank&#34;&gt;WebAssembly 2.0 Specification Finalized&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li class=&#34;hn-story&#34;&gt;&lt;a href=&#34;https://www.infoq.com/news/2025/04/rust-in-linux-kernel-expands/&#34; target=&#34;_blank&#34;&gt;Rust in Linux Kernel Expands to Network Subsystems&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li class=&#34;hn-story&#34;&gt;&lt;a href=&#34;https://www.wired.com/story/right-to-repair-wins-2025/&#34; target=&#34;_blank&#34;&gt;Right to Repair Movement Secures Major Legal Victory&lt;/a&gt;&lt;/li&gt;&#xA;    &lt;li class=&#34;hn-story&#34;&gt;&lt;a href=&#34;https://spectrum.ieee.org/quantum-supremacy-2025&#34; target=&#34;_blank&#34;&gt;New Quantum Computer Achieves True Quantum Advantage&lt;/a&gt;&lt;/li&gt;&#xA;  &lt;/ul&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;  .hn-feed { margin: 2rem 0; }&#xA;  .hn-stories { list-style-type: none; padding: 0; }&#xA;  .hn-story { margin-bottom: 1rem; padding-bottom: 0.5rem; border-bottom: 1px solid #eee; }&#xA;  .hn-story a { font-weight: bold; text-decoration: none; }&#xA;&lt;/style&gt;&#xD;&#xA;&#xA;&lt;p&gt;&lt;em&gt;This feed is automatically updated from &lt;a href=&#34;https://news.ycombinator.com/newest&#34;&gt;Hacker News&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Showcase</title>
      <link>https://letungbach.com/showcase/</link>
      <pubDate>Tue, 01 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/showcase/</guid>
      <description>&lt;h1 id=&#34;project-showcase&#34;&gt;Project Showcase&lt;/h1&gt;&#xA;&lt;h2 id=&#34;ai-projects--research&#34;&gt;AI Projects &amp;amp; Research&lt;/h2&gt;&#xA;&lt;h3 id=&#34;multi-ai-agents-system--giongai-2025&#34;&gt;Multi AI Agents System @ giong.ai (2025)&lt;/h3&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://letungbach.com/images/ai-agents-placeholder.jpg&#34; alt=&#34;AI Agents System&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;An advanced orchestration system that enables multiple AI agents to collaborate on complex tasks. Built with state-of-the-art machine learning techniques and deployed on MCP servers.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Key Features:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Distributed problem-solving across specialized AI agents&lt;/li&gt;&#xA;&lt;li&gt;Self-optimization and learning capabilities&lt;/li&gt;&#xA;&lt;li&gt;Scalable architecture for enterprise applications&lt;/li&gt;&#xA;&lt;li&gt;Real-time collaboration and knowledge sharing&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;graphrag-for-supply-chain-transparency&#34;&gt;GraphRAG for Supply Chain Transparency&lt;/h3&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://letungbach.com/images/supply-chain-placeholder.jpg&#34; alt=&#34;Supply Chain Transparency&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>MoE-JEPA</title>
      <link>https://letungbach.com/posts/moe-jepa/</link>
      <pubDate>Mon, 31 Mar 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/moe-jepa/</guid>
      <description>&lt;h1 id=&#34;research-proposal-moe-jepa-world-models-for-efficient-reinforcement-learning-and-planning&#34;&gt;Research Proposal: MoE-JEPA World Models for Efficient Reinforcement Learning and Planning&lt;/h1&gt;&#xA;&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;&#xA;&lt;p&gt;Current AI research emphasizes the development of sophisticated world models capable of understanding complex dynamics, particularly from video data, often leveraging self-supervised learning (SSL) for representation extraction. Predictive models in abstract spaces (like JEPA) are gaining prominence over generative ones. Simultaneously, Mixture of Experts (MoE) offers a way to scale neural network capacity efficiently. This proposal outlines a research approach combining these trends: developing an Action-Conditioned Mixture-of-Experts Joint-Embedding Predictive Architecture (MoE-JEPA) world model. This model will be pre-trained using self-supervision on large video datasets to learn robust visual representations and environment dynamics. The MoE structure will allow the model to efficiently capture diverse or multi-modal dynamics within an environment by routing inputs to specialized expert sub-networks. This sophisticated world model will then be integrated into a model-based Reinforcement Learning (RL) framework to enable efficient planning and decision-making for agents (e.g., robots) interacting with complex environments. We hypothesize that this approach will lead to more accurate world models, improved sample efficiency in RL, and better generalization across tasks compared to monolithic world models.&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>https://letungbach.com/posts/ai-tools/ai-tools/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/ai-tools/ai-tools/</guid>
      <description>&lt;p&gt;Research Rabbit&lt;/p&gt;&#xA;&lt;p&gt;Book writing&#xA;&lt;a href=&#34;https://www.story.com/&#34;&gt;https://www.story.com/&lt;/a&gt;&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;text to video&lt;/th&gt;&#xA;          &lt;th&gt;Image gen&lt;/th&gt;&#xA;          &lt;th&gt;Audio Gen&lt;/th&gt;&#xA;          &lt;th&gt;Code Assist&lt;/th&gt;&#xA;          &lt;th&gt;Play Ground&lt;/th&gt;&#xA;          &lt;th&gt;OCR&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;!-- raw HTML omitted --&gt;&lt;a href=&#34;https://higgsfield.ai/&#34;&gt;Higgsfield AI&lt;/a&gt;&lt;!-- raw HTML omitted --&gt;&lt;a href=&#34;https://openai.com/index/sora/&#34;&gt;Sora&lt;/a&gt;&lt;!-- raw HTML omitted --&gt;&lt;a href=&#34;https://www.heygen.com/?sid=rewardful&amp;amp;via=sale&#34;&gt;HeyGen&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;midjourney&lt;!-- raw HTML omitted --&gt;&lt;/td&gt;&#xA;          &lt;td&gt;mureka.ai&lt;!-- raw HTML omitted --&gt;suno.ai&lt;/td&gt;&#xA;          &lt;td&gt;Anthropic claude &lt;!-- raw HTML omitted --&gt;Google gemini pro&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://playground.allenai.org/&#34;&gt;https://playground.allenai.org/&lt;/a&gt;&lt;!-- raw HTML omitted --&gt;&lt;!-- raw HTML omitted --&gt;&lt;a href=&#34;https://openrouter.ai/&#34;&gt;https://openrouter.ai/&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://olmocr.allenai.org/&#34;&gt;https://olmocr.allenai.org/&lt;/a&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://pikartai.com/&#34;&gt;Pika&lt;/a&gt; (iOS)&lt;/td&gt;&#xA;          &lt;td&gt;davinci&lt;!-- raw HTML omitted --&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Meta&amp;rsquo;s &lt;!-- raw HTML omitted --&gt;&#x9;Mocha, &lt;!-- raw HTML omitted --&gt;&#x9;Movie Gen&lt;/td&gt;&#xA;          &lt;td&gt;chatgpt 4o image gen&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Github:&lt;!-- raw HTML omitted --&gt;- &lt;a href=&#34;https://github.com/TIGER-AI-Lab/AnyV2V&#34;&gt;Tiger&lt;/a&gt;&lt;!-- raw HTML omitted --&gt;- &lt;a href=&#34;https://github.com/comfyanonymous/ComfyUI&#34;&gt;ComfyUI&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;ByteDance Tiktok: &lt;!-- raw HTML omitted --&gt;- &lt;strong&gt;INFP&lt;/strong&gt;, &lt;!-- raw HTML omitted --&gt;- &lt;a href=&#34;https://github.com/bytedance/InfiniteYou&#34;&gt;InfiniteYou&lt;/a&gt; (PuLID-FLUX),  &lt;!-- raw HTML omitted --&gt;- &lt;a href=&#34;https://saiyan-world.github.io/goku/&#34;&gt;Goku&lt;/a&gt;&lt;!-- raw HTML omitted --&gt;- DreamActor-M1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Runway&lt;!-- raw HTML omitted --&gt;LumaLabs&lt;!-- raw HTML omitted --&gt;Kling&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;!-- raw HTML omitted --&gt;&lt;a href=&#34;https://hailuoai.video/&#34;&gt;Hailuo&lt;/a&gt;&lt;!-- raw HTML omitted --&gt;&lt;a href=&#34;https://github.com/hexiaochun/hailuo_api_proxy&#34;&gt;account&lt;/a&gt;&lt;!-- raw HTML omitted --&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;Cookbook&#xA;&lt;a href=&#34;https://github.com/togethercomputer/together-cookbook&#34;&gt;https://github.com/togethercomputer/together-cookbook&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>https://letungbach.com/posts/ai-tools/fine-tuning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/ai-tools/fine-tuning/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.together.ai/&#34;&gt;https://www.together.ai/&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>https://letungbach.com/posts/ai-tools/prompt/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/ai-tools/prompt/</guid>
      <description>&lt;p&gt;Create a comprehensive, step-by-step guide detailing all available methods (both technical and non-technical) to scrape or crawl data from Facebook, including public and private data. A detailed, well-structured document or guide with headings, subheadings, bullet points, and examples. The guide should cover technical considerations, tools, techniques, and potential risks.&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Overview of Facebook data scraping/crawling.&#xA;Facebook‚Äôs Terms of Service and Community Standards.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Types of Facebook Data&#xA;Public data (e.g., public posts, pages, groups).&#xA;Private data (e.g., private profiles, messages, friend lists).&#xA;Metadata (e.g., likes, shares, comments, timestamps).&#xA;Methods for Scraping Public Facebook Data&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>https://letungbach.com/posts/benchmarks/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/benchmarks/</guid>
      <description></description>
    </item>
    <item>
      <title>Search</title>
      <link>https://letungbach.com/search/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/search/</guid>
      <description></description>
    </item>
  </channel>
</rss>
