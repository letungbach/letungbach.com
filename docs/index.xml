<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Le Tung Bach, Ph.D.</title>
    <link>https://letungbach.com/</link>
    <description>Recent content on Le Tung Bach, Ph.D.</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Fri, 11 Apr 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://letungbach.com/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>MAAS</title>
      <link>https://letungbach.com/posts/multi-ai-agent-system/</link>
      <pubDate>Fri, 11 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/multi-ai-agent-system/</guid>
      <description>&lt;p&gt;The next generation of AI Agents is not just smarter&lt;/p&gt;&#xA;&lt;p&gt;They will be fundamentally different, Let me explain&amp;hellip;&lt;/p&gt;&#xA;&lt;p&gt;Sam Altman in a recent Reddit AMA emphasized the popularity of AI Agents.&lt;br&gt;&#xA;(Learn more here: &lt;a href=&#34;https://lnkd.in/gzTFADZM&#34;&gt;https://lnkd.in/gzTFADZM&lt;/a&gt;)&lt;/p&gt;&#xA;&lt;p&gt;These AI Agents can clearly accelerate the development of different fields.&lt;/p&gt;&#xA;&lt;p&gt;However, it is certain that their architecture will greatly differ from our current architecture.&lt;/p&gt;&#xA;&lt;p&gt;Though we cannot exactly predict the future architecture.&lt;/p&gt;&#xA;&lt;p&gt;Here is my take on a possible architectural change within AI agents:&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Prompts</title>
      <link>https://letungbach.com/posts/prompts/</link>
      <pubDate>Thu, 10 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/prompts/</guid>
      <description>&lt;h5 id=&#34;10-prompt-templates-cho-rlms-sử-dụng-framework-thinking--reasoning&#34;&gt;10 Prompt Templates cho RLMs sử dụng Framework Thinking / Reasoning&lt;/h5&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://wsgxall6ggaw.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=YmEzYjAwNTE4ZmM2MTYyNDcyMGY4NTljNzk3MWFlZGNfWTk1cE5ZQkR1UzBFYUY5a1JRbXU5bWJYemhLenJBTWpfVG9rZW46TWd1M2JqOHh3b0J1ZWR4N3lOUWxsd0N1Z3VnXzE3NDQyMjAyNDc6MTc0NDIyMzg0N19WNA&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;**Phù hợp dùng cho Claude 3.7 Sonnet&lt;/p&gt;&#xA;&lt;p&gt;Dưới đây là các prompt template đơn giản và trực tiếp để tận dụng tối đa khả năng reasoning của RLMs, kết hợp với các framework thinking. Mỗi template được thiết kế để tối ưu hóa quá trình lý luận có cấu trúc.&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;MCTS-Based Strategy Analysis Template&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://wsgxall6ggaw.sg.larksuite.com/space/api/box/stream/download/asynccode/?code=MWRjYzYzYjUwMjc4ZDI5YTE5ZDliODFjNmU5Nzc3OGFfdnZPMjR1MzJ4eGUydmR2MVlTaWJ5ZmNCOUJGWVVLenlfVG9rZW46U0dyRGJkdVJDbzg1NlF4SG9vRWxNR1paZ2FjXzE3NDQyMjAyNDc6MTc0NDIyMzg0N19WNA&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;ol start=&#34;2&#34;&gt;&#xA;&lt;li&gt;&lt;code&gt;&amp;lt;reasoning&amp;gt;&lt;/code&gt; &lt;code&gt;Apply Monte Carlo Tree Search reasoning to systematically explore business environment factors and their competitive impacts. Branch out from core industry analysis to specific forces, evaluating each path&#39;s strategic implications.&lt;/code&gt; &lt;code&gt;&amp;lt;/reasoning&amp;gt;&lt;/code&gt; &lt;code&gt;&amp;lt;task&amp;gt;&lt;/code&gt; &lt;code&gt;Analyze [Business Situation] using Porter&#39;s Five Forces:&lt;/code&gt; &lt;code&gt;Root: Current competitive landscape&lt;/code&gt; &lt;code&gt;Explore branches:&lt;/code&gt; &lt;code&gt;Evaluate impact on [Business Outcome]&lt;/code&gt; &lt;code&gt;Develop strategic recommendations&lt;/code&gt; &lt;code&gt;&amp;lt;/task&amp;gt;&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h6 id=&#34;giải-thích&#34;&gt;Giải thích:&lt;/h6&gt;&#xA;&lt;p&gt;Template này áp dụng phương pháp MCTS với Porter&amp;rsquo;s Five Forces, tạo cấu trúc lý luận dạng cây với các nhánh tương ứng với mỗi thành phần. RLM khám phá từng nhánh và lan truyền insights để tạo chiến lược toàn diện.&lt;/p&gt;</description>
    </item>
    <item>
      <title>benchmark</title>
      <link>https://letungbach.com/posts/benchmark/</link>
      <pubDate>Thu, 10 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/benchmark/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://arcprize.org/leaderboard?fbclid=IwY2xjawJkGOJleHRuA2FlbQIxMAABHpInxwGwuzaVHnGeNNycEGfhmweu8Xb_aBq5dhGnOHLm1qEbktYZYnqZzNmc_aem_ttSWRTegPXjvOSU1K0DAlg&#34;&gt;https://arcprize.org/leaderboard?fbclid=IwY2xjawJkGOJleHRuA2FlbQIxMAABHpInxwGwuzaVHnGeNNycEGfhmweu8Xb_aBq5dhGnOHLm1qEbktYZYnqZzNmc_aem_ttSWRTegPXjvOSU1K0DAlg&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;![[Pasted image 20250410103636.png]]![[Pasted image 20250410103702.png]]&lt;/p&gt;</description>
    </item>
    <item>
      <title>bookpublishing</title>
      <link>https://letungbach.com/posts/book-publishing/</link>
      <pubDate>Thu, 10 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/book-publishing/</guid>
      <description>&lt;p&gt;Wikimedia Commons does not provide ISBNs for ebooks or books, as it is primarily a platform for sharing free media files like images, videos, and audio under open licenses.&lt;/p&gt;&#xA;&lt;p&gt;If you&amp;rsquo;re looking to publish your book and obtain a free ISBN, here are some platforms that can help:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Amazon Kindle Direct Publishing (KDP)&lt;/strong&gt;: Offers free ISBNs for ebooks and print books. It&amp;rsquo;s a popular choice for self-publishing.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;IngramSpark&lt;/strong&gt;: Provides free ISBNs for U.S.-based self-publishers.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Pencil&lt;/strong&gt;: A self-publishing platform that generates free ISBNs for your book and distributes it globally in ebook and paperback formats.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Draft2Digital&lt;/strong&gt;: A user-friendly platform for publishing ebooks with free ISBNs.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;These platforms not only provide ISBNs but also help distribute your book to major retailers. Let me know if you&amp;rsquo;d like more details about any of these options!&lt;/p&gt;</description>
    </item>
    <item>
      <title>emoji submission</title>
      <link>https://letungbach.com/posts/emoji/</link>
      <pubDate>Thu, 10 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/emoji/</guid>
      <description>&lt;p&gt;By Vietnamese artist - Itourvn, Public Domain, &lt;a href=&#34;https://commons.wikimedia.org/w/index.php?curid=134955722&#34;&gt;https://commons.wikimedia.org/w/index.php?curid=134955722&lt;/a&gt;&#xA;&lt;a href=&#34;https://en.wikipedia.org/wiki/Four_Immortals&#34;&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/5/5e/Giong_emoji_Black%26White_original_size.png/120px-Giong_emoji_Black%26White_original_size.png&#34; alt=&#34;Four Immortals - Wikipedia&#34;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;Thanh Giong emoji:&lt;/p&gt;&#xA;&lt;p&gt;![[Pasted image 20250410000642.png]]&#xA;&lt;a href=&#34;https://commons.wikimedia.org/w/index.php?title=Special:QrCode&amp;amp;url=https%3A%2F%2Fcommons.wikimedia.org%2Fw%2Findex.php%3Ftitle%3DSpecial%3AUrlShortener%26url%3Dhttps%253A%252F%252Fcommons.wikimedia.org%252Fwiki%252FSpecial%253AUploadWizard&#34;&gt;https://commons.wikimedia.org/w/index.php?title=Special:QrCode&amp;url=https%3A%2F%2Fcommons.wikimedia.org%2Fw%2Findex.php%3Ftitle%3DSpecial%3AUrlShortener%26url%3Dhttps%253A%252F%252Fcommons.wikimedia.org%252Fwiki%252FSpecial%253AUploadWizard&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;[[File:Giong emoji color original size.png|thumb|Thanh Giong (Vietnamese Hero) Saint-Giong emoji color original size]]&#xA;&lt;a href=&#34;https://commons.wikimedia.org/wiki/File:Giong_emoji_color_original_size.png&#34;&gt;https://commons.wikimedia.org/wiki/File:Giong_emoji_color_original_size.png&lt;/a&gt;&#xA;&lt;a href=&#34;https://commons.wikimedia.org/wiki/File:Giong_emoji_color_original_size.png&#34;&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/9/99/Giong_emoji_color_original_size.png/120px-Giong_emoji_color_original_size.png&#34; alt=&#34;Thanh Giong Color Emoji&#34;&gt;&lt;/a&gt;&#xA;&lt;a href=&#34;https://w.wiki/Dkqc&#34;&gt;https://w.wiki/Dkqc&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;[[File:Giong emoji Gray-scale original size.png|thumb|Thanh Giong (Vietnamese Hero) Saint-Giong Gray-scale emoji original size]]&#xA;&lt;a href=&#34;https://commons.wikimedia.org/wiki/File:Giong_emoji_Gray-scale_original_size.png&#34;&gt;https://commons.wikimedia.org/wiki/File:Giong_emoji_Gray-scale_original_size.png&lt;/a&gt;&#xA;&lt;a href=&#34;https://commons.wikimedia.org/wiki/File:Giong_emoji_Gray-scale_original_size.png&#34;&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/8/87/Giong_emoji_Gray-scale_original_size.png/120px-Giong_emoji_Gray-scale_original_size.png&#34; alt=&#34;Thanh Giong Gray-scale Emoji&#34;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;[[File:Giong emoji Black&amp;amp;White original size.png|thumb|Thanh Giong (Vietnamese Hero) Saint-Giong in black and white version]]&#xA;&lt;a href=&#34;https://commons.wikimedia.org/wiki/File:Giong_emoji_Black%26White_original_size.png&#34;&gt;https://commons.wikimedia.org/wiki/File:Giong_emoji_Black%26White_original_size.png&lt;/a&gt;&#xA;&lt;a href=&#34;https://commons.wikimedia.org/wiki/File:Giong_emoji_Black%26White_original_size.png&#34;&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/5/5e/Giong_emoji_Black%26White_original_size.png/120px-Giong_emoji_Black%26White_original_size.png&#34; alt=&#34;Thanh Giong Black &amp;amp; White Emoji&#34;&gt;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;![[Pasted image 20250410001306.png]]&#xA;&lt;a href=&#34;https://creativecommons.org/licenses/by/3.0/&#34;&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/2/24/CC-BY_icon.svg/120px-CC-BY_icon.svg.png&#34; alt=&#34;Creative Commons License&#34;&gt;&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Games</title>
      <link>https://letungbach.com/game/</link>
      <pubDate>Thu, 10 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/game/</guid>
      <description>&lt;h1 id=&#34;games&#34;&gt;Games&lt;/h1&gt;&#xA;&lt;h2 id=&#34;snake-game&#34;&gt;Snake Game&lt;/h2&gt;&#xA;&lt;p&gt;Play the classic Snake Game! Navigate the snake to eat food and grow longer, but avoid colliding with walls or yourself.&lt;/p&gt;&#xA;&#xD;&#xA;&lt;iframe src=&#34;https://letungbach.com/game/snake.html&#34; style=&#34;width:100%; height:650px; border:none; max-width:820px; margin:0 auto; display:block;&#34;&gt;&lt;/iframe&gt;&#xD;&#xA;&#xA;&lt;h2 id=&#34;mario-game&#34;&gt;Mario Game&lt;/h2&gt;&#xA;&lt;p&gt;Enjoy the Mario-style platformer! Navigate through platforms, collect coins, and try not to fall.&lt;/p&gt;&#xA;&#xD;&#xA;&lt;iframe src=&#34;https://letungbach.com/game/mario.html&#34; style=&#34;width:100%; height:450px; border:none; max-width:820px; margin:0 auto; display:block;&#34;&gt;&lt;/iframe&gt;</description>
    </item>
    <item>
      <title>Self-Rag</title>
      <link>https://letungbach.com/posts/self-rag/</link>
      <pubDate>Thu, 10 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/self-rag/</guid>
      <description>&lt;p&gt;**&lt;/p&gt;&#xA;&lt;h1 id=&#34;advancing-agentic-knowledgeable-self-awareness-a-research-agenda-extending-arxiv250403553&#34;&gt;Advancing Agentic Knowledgeable Self-Awareness: A Research Agenda Extending arXiv:2504.03553&lt;/h1&gt;&#xA;&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;&#xA;&lt;p&gt;The development of artificial intelligence (AI) agents capable of complex tasks necessitates mechanisms for robust and efficient knowledge utilization. A critical aspect of this is self-awareness regarding the agent&amp;rsquo;s own knowledge state – understanding what it knows, what it doesn&amp;rsquo;t know, and when external information is required. The paper arXiv:2504.03553 introduces the concept of &amp;ldquo;agentic knowledgeable self-awareness&amp;rdquo; and proposes the &amp;ldquo;KnowSelf&amp;rdquo; method as a novel approach to instill this capability in language agents. KnowSelf utilizes special tokens and a two-stage training process to explicitly signal the agent&amp;rsquo;s perceived knowledge state and guide its information processing strategy (e.g., relying on internal parameters vs. seeking external knowledge).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Trend</title>
      <link>https://letungbach.com/posts/trend/</link>
      <pubDate>Thu, 10 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/trend/</guid>
      <description>&lt;p&gt;If you&amp;rsquo;re looking for tools to track trends beyond Google Trends, here are some great alternatives:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Exploding Topics&lt;/strong&gt;: Helps discover emerging trends before they become mainstream. It&amp;rsquo;s ideal for marketers and entrepreneurs.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;SEMrush Trends&lt;/strong&gt;: A comprehensive tool for analyzing industry trends and competitive insights.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;BuzzSumo&lt;/strong&gt;: Focuses on social media trends and content performance.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Pinterest Trends&lt;/strong&gt;: Tracks trending topics and ideas on Pinterest.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Trend Hunter&lt;/strong&gt;: A platform for discovering consumer insights and innovation trends.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Treendly&lt;/strong&gt;: Offers trend data across various platforms like Google, YouTube, and Amazon.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Keyword Tool&lt;/strong&gt;: Provides keyword trends and search volume data.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;TrendWatchers&lt;/strong&gt;: Specializes in YouTube trend tracking.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;SparkToro&lt;/strong&gt;: Focuses on audience insights and trending topics.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Muck Rack&lt;/strong&gt;: Tracks trends in journalism and media.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;Each tool has its unique strengths, so the best choice depends on your specific needs. Let me know if you&amp;rsquo;d like more details about any of these!&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ethical Intelligence</title>
      <link>https://letungbach.com/posts/ethical-intelligence/</link>
      <pubDate>Sun, 06 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/ethical-intelligence/</guid>
      <description>&lt;h1 id=&#34;ethical-intelligence-in-the-era-of-al-navigating-the-post-turing-landscape&#34;&gt;Ethical Intelligence in the Era of Al: Navigating the Post-Turing Landscape&lt;/h1&gt;&#xA;&lt;p&gt;The rapid advancement of artificial intelligence (Al) has ignited a global conversation about its potential benefits and inherent risks. The unease expressed by authors in London regarding the alleged unauthorized use of their work to train Al models underscores a growing concern within the creative ecosystem. This is not an isolated incident, but rather a symptom of a larger challenge: how to ethically integrate increasingly sophisticated Al into the fabric of our society, particularly within creative and political spheres where human values and rights are paramount. The deployment of Al in support of regimes committing atrocities further amplifies the urgency of establishing ethical boundaries for this powerful technology. It is no longer a question of whether unchecked Al will significantly impact these ecosystems, but rather how quickly and with what consequences. This paper will delve into the concept of &amp;ldquo;Ethical Intelligence&amp;rdquo; in the context of Al that is reaching, and in some interpretations, surpassing human-level conversational abilities, as symbolized by the Turing Test.&lt;/p&gt;</description>
    </item>
    <item>
      <title>movie</title>
      <link>https://letungbach.com/posts/movie-list/</link>
      <pubDate>Fri, 04 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/movie-list/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.phephim.lol/phim-bo/cuoc-doi-duc-phat&#34;&gt;https://www.phephim.lol/phim-bo/cuoc-doi-duc-phat&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Continual Learning</title>
      <link>https://letungbach.com/posts/continual-learning/</link>
      <pubDate>Wed, 02 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/continual-learning/</guid>
      <description>&lt;p&gt;**&lt;/p&gt;&#xA;&lt;h1 id=&#34;continual-learning-a-review-of-variational-dropout-mixture-of-experts-with-prompting-and-backdoor-attacks&#34;&gt;Continual Learning: A Review of Variational Dropout, Mixture of Experts with Prompting, and Backdoor Attacks&lt;/h1&gt;&#xA;&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;&#xA;&lt;p&gt;The field of machine learning has witnessed significant advancements in recent years, enabling models to achieve remarkable performance on a wide array of tasks. However, a fundamental challenge arises when these models are deployed in dynamic environments where new data or tasks are encountered sequentially. This paradigm, known as continual learning, necessitates the ability of a model to learn from a continuous stream of information without forgetting previously acquired knowledge.1 A major impediment to achieving this goal is catastrophic forgetting, a phenomenon where the learning of new information leads to a drastic decline in performance on previously learned tasks.4 Overcoming this challenge requires specialized techniques that can maintain a delicate balance between the model&amp;rsquo;s capacity to learn new tasks (plasticity) and its ability to retain old knowledge (stability).4&lt;/p&gt;</description>
    </item>
    <item>
      <title>About</title>
      <link>https://letungbach.com/about/</link>
      <pubDate>Tue, 01 Apr 2025 17:53:32 +0700</pubDate>
      <guid>https://letungbach.com/about/</guid>
      <description>&lt;h1 id=&#34;le-tung-bach-phd&#34;&gt;Le Tung Bach, Ph.D.&lt;/h1&gt;&#xA;&lt;p&gt;&lt;strong&gt;AI Researcher &amp;amp; Tech Adoption Specialist | Sustainable Ecosystem Management | Secured &amp;gt;$97M+ ODA International Credit Funding | Art &amp;amp; Technology Innovator&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Founder: unitedcoffee.vn, mulala.art, giong.ai&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;📞 0906 376 868 | 📍 Hanoi, Vietnam | 📧 &lt;a href=&#34;mailto:b@giong.ai&#34;&gt;b@giong.ai&lt;/a&gt; | 🔗 &lt;a href=&#34;https://orcid.org/0009-0006-3525-6710&#34;&gt;https://orcid.org/0009-0006-3525-6710&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;about&#34;&gt;About&lt;/h2&gt;&#xA;&lt;p&gt;Multidisciplinary AI expert with a Ph.D. in Management and extensive experience in research administration, grant writing, and financial oversight of large-scale research projects. Successfully secured and managed $97M+ in international ODA funding (AFD, World Bank, ADB, JAICA) and have a proven track record in grant application processes, compliance, and project monitoring. Expert at faculty support, interdisciplinary research collaboration, and optimizing research resources to enhance institutional impact. Passionate about advancing Vietnamese research institutions&amp;rsquo; access to international funding.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Moe-JEPA vs Titan vs FAN</title>
      <link>https://letungbach.com/posts/moe-jepa-vs-titan-vs-fan/</link>
      <pubDate>Tue, 01 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/moe-jepa-vs-titan-vs-fan/</guid>
      <description>&lt;p&gt;make a markdown code about the following content:&lt;/p&gt;&#xA;&lt;h1 id=&#34;comparative-analysis-of-advanced-ai-architectures-fourier-analysis-networks-google-titan-transformer-20-and-moe-jepa-world-models&#34;&gt;Comparative Analysis of Advanced AI Architectures: Fourier Analysis Networks, Google Titan Transformer 2.0, and MoE-JEPA World Models&lt;/h1&gt;&#xA;&lt;p&gt;The field of artificial intelligence has experienced remarkable evolution with several novel architectures emerging to address the limitations of conventional deep learning approaches. This research provides a comprehensive comparative analysis of three cutting-edge AI architectures: Fourier Analysis Networks (FANs), Google Titan Transformer 2.0, and Mixture of Experts Joint Embedding Predictive Architecture (MoE-JEPA) World Models. Each model employs distinct approaches to overcome current AI limitations, particularly in handling periodic structures, long-term dependencies, and context understanding. Through detailed examination of their architectures, operational mechanisms, advantages, limitations, and empirical performance, this study offers insights into their potential impact on the future trajectory of artificial intelligence research and applications.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Researcher list</title>
      <link>https://letungbach.com/posts/list-researchers/</link>
      <pubDate>Tue, 01 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/list-researchers/</guid>
      <description>&lt;h1 id=&#34;yann-lecun-the-future-beyond-generative-ai&#34;&gt;Yann LeCun: The Future Beyond Generative AI&lt;/h1&gt;&#xA;&lt;p&gt;12 sources&lt;/p&gt;&#xA;&lt;p&gt;The provided transcripts capture various discussions and lectures primarily focusing on the evolution, capabilities, limitations, and societal implications of artificial intelligence and deep learning. &lt;strong&gt;Experts like Geoffrey Hinton, Yann LeCun, and Fei-Fei Li reflect on breakthroughs such as deep neural networks and large language models, including their own significant contributions.&lt;/strong&gt; They discuss the future trajectory of AI research, highlighting the importance of world models, different learning approaches like joint embedding, and the distinctions between human and artificial intelligence. &lt;strong&gt;Concerns surrounding responsible AI development, potential misuse, and the need for open-source platforms are also prominent themes.&lt;/strong&gt; Additionally, personal anecdotes about the speakers&amp;rsquo; journeys and perspectives on the field enrich the content. &lt;strong&gt;The conversations explore both the technical advancements and the broader philosophical and ethical questions raised by increasingly sophisticated AI.&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>RSS News Feed</title>
      <link>https://letungbach.com/rss/</link>
      <pubDate>Tue, 01 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/rss/</guid>
      <description>&lt;h1 id=&#34;latest-tech-news&#34;&gt;Latest Tech News&lt;/h1&gt;&#xA;&lt;p&gt;This page automatically pulls the latest news from Hacker News. Stay updated with the newest developments in technology, programming, and startup culture.&lt;/p&gt;&#xA;&lt;h2 id=&#34;recent-headlines&#34;&gt;Recent Headlines&lt;/h2&gt;&#xA;&lt;div class=&#34;hn-feed&#34;&gt;&#xD;&#xA;  &lt;ul class=&#34;hn-stories&#34;&gt;&#xD;&#xA;    &lt;li class=&#34;hn-story&#34;&gt;Loading latest news...&lt;/li&gt;&#xD;&#xA;  &lt;/ul&gt;&#xD;&#xA;&lt;/div&gt;&#xD;&#xA;&lt;style&gt;&#xD;&#xA;  .hn-feed { margin: 2rem 0; }&#xD;&#xA;  .hn-stories { list-style-type: none; padding: 0; }&#xD;&#xA;  .hn-story { margin-bottom: 1rem; padding-bottom: 0.5rem; border-bottom: 1px solid #eee; }&#xD;&#xA;  .hn-story a { font-weight: bold; text-decoration: none; }&#xD;&#xA;&lt;/style&gt;&#xD;&#xA;&lt;script src=&#34;https://letungbach.com/js/hn-feed.js&#34; defer&gt;&lt;/script&gt;&#xD;&#xA;&lt;p&gt;&lt;em&gt;This feed is automatically updated from &lt;a href=&#34;https://news.ycombinator.com/newest&#34;&gt;Hacker News&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Showcase</title>
      <link>https://letungbach.com/showcase/</link>
      <pubDate>Tue, 01 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/showcase/</guid>
      <description>&lt;h1 id=&#34;project-showcase&#34;&gt;Project Showcase&lt;/h1&gt;&#xA;&lt;h2 id=&#34;ai-projects--research&#34;&gt;AI Projects &amp;amp; Research&lt;/h2&gt;&#xA;&lt;h3 id=&#34;multi-ai-agents-system--giongai-2025&#34;&gt;Multi AI Agents System @ giong.ai (2025)&lt;/h3&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://letungbach.com/images/ai-agents-placeholder.jpg&#34; alt=&#34;AI Agents System&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;An advanced orchestration system that enables multiple AI agents to collaborate on complex tasks. Built with state-of-the-art machine learning techniques and deployed on MCP servers.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Key Features:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Distributed problem-solving across specialized AI agents&lt;/li&gt;&#xA;&lt;li&gt;Self-optimization and learning capabilities&lt;/li&gt;&#xA;&lt;li&gt;Scalable architecture for enterprise applications&lt;/li&gt;&#xA;&lt;li&gt;Real-time collaboration and knowledge sharing&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;graphrag-for-supply-chain-transparency&#34;&gt;GraphRAG for Supply Chain Transparency&lt;/h3&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://letungbach.com/images/supply-chain-placeholder.jpg&#34; alt=&#34;Supply Chain Transparency&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>MoE-JEPA</title>
      <link>https://letungbach.com/posts/moe-jepa/</link>
      <pubDate>Mon, 31 Mar 2025 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/posts/moe-jepa/</guid>
      <description>&lt;h1 id=&#34;research-proposal-moe-jepa-world-models-for-efficient-reinforcement-learning-and-planning&#34;&gt;Research Proposal: MoE-JEPA World Models for Efficient Reinforcement Learning and Planning&lt;/h1&gt;&#xA;&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;&#xA;&lt;p&gt;Current AI research emphasizes the development of sophisticated world models capable of understanding complex dynamics, particularly from video data, often leveraging self-supervised learning (SSL) for representation extraction. Predictive models in abstract spaces (like JEPA) are gaining prominence over generative ones. Simultaneously, Mixture of Experts (MoE) offers a way to scale neural network capacity efficiently. This proposal outlines a research approach combining these trends: developing an Action-Conditioned Mixture-of-Experts Joint-Embedding Predictive Architecture (MoE-JEPA) world model. This model will be pre-trained using self-supervision on large video datasets to learn robust visual representations and environment dynamics. The MoE structure will allow the model to efficiently capture diverse or multi-modal dynamics within an environment by routing inputs to specialized expert sub-networks. This sophisticated world model will then be integrated into a model-based Reinforcement Learning (RL) framework to enable efficient planning and decision-making for agents (e.g., robots) interacting with complex environments. We hypothesize that this approach will lead to more accurate world models, improved sample efficiency in RL, and better generalization across tasks compared to monolithic world models.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Chat</title>
      <link>https://letungbach.com/chat/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/chat/</guid>
      <description>&lt;p&gt;Welcome to the chat interface! This is a secure implementation using the Groq API.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Search</title>
      <link>https://letungbach.com/search/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://letungbach.com/search/</guid>
      <description></description>
    </item>
  </channel>
</rss>
